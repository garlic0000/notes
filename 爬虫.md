selenium获取请求信息

主要获取请求头信息

```
https://www.jianshu.com/p/615e3c0140a5
# caps构造
https://stackoverflow.com/questions/57602974/gmail-is-blocking-login-via-automation-selenium
https://stackoverflow.com/questions/56812190/protractor-log-type-performance-not-found-error
```

retry装饰器

```
https://www.cnblogs.com/fanjp666888/p/9796943.html
https://blog.csdn.net/liereli/article/details/79993114
```

contenttype

```
https://www.cnblogs.com/fighter007/p/10917026.html
```

formdata

```
https://www.cnblogs.com/xiaocaiyuxiaoniao/p/9430878.html
```

bytesio()

```
https://www.cnblogs.com/yqpy/p/8556090.html
```

bufferedreader()

## `selenium`

```
http://blog.az009.com/14686.html
https://selenium-python.readthedocs.io/api.html
# 下载chrome driver
http://chromedriver.storage.googleapis.com/index.html
```

1.声明浏览器对象

```
from selenium import webdriver
```

`webdriver`可以认为是浏览器的驱动器，要驱动浏览器必须用到`webdriver`，支持多种浏览器

```
webdriver.Firefox
webdriver.FirefoxProfile
webdriver.Chrome
webdriver.ChromeOptions
webdriver.Ie
webdriver.Opera
webdriver.PhantomJS
webdriver.Remote
webdriver.DesiredCapabilities
webdriver.ActionChains
webdriver.TouchActions
webdriver.Proxy
```

2.访问页面

```
from selenium import webdriver
driver = webdriver.Chrome()
driver.get('https://www.taobao.com')
print(driver.page_source)           #driver.page_source是获取网页的全部html 
browser.close()
```

3.查找元素

单个元素

```
from selenium import webdriver
browser = webdriver.Chrome()
browser.get('https://www.taobao.com')
input_first = browser.find_element_by_id('q')
input_second = browser.find_element_by_css_selector('#q') 
input_third = browser.find_element_by_xpath('//*[@id="q"]')
print(input_first,input_second,input_third)
browser.close()
# close 关闭最初的window, quit 关闭所有的window
```

常用的查找方法

```
find_element_by_name
find_element_by_xpath
find_element_by_link_text
find_element_by_partial_link_text
find_element_by_tag_name
find_element_by_class_name
find_element_by_css_selector
```

使用通用的方法

```
from selenium import webdriver
from selenium.webdriver.common.by import By
browser = webdriver.Chrome()
browser.get('https://www.taobao.com')
input_first = browser.find_element(BY.ID,'q')#第一个参数传入名称，第二个传入具体的参数 
print(input_first)
browser.close()
```

多个元素，elements多个s

```
input_first = browser.find_elements_by_id('q')
```

4.元素交互操作

```
from selenium import webdriver
import time
browser = webdriver.Chrome()
browser.get('https://www.taobao.com')
input = browser.find_element_by_id('q')#找到搜索框 
input.send_keys('iPhone')#传送入关键词 
time.sleep(5)
input.clear()#清空搜索框 
input.send_keys('男士内裤')
button = browser.find_element_by_class_name('btn-search')#找到搜索按钮 
button.click()
```

更多操作: http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement#可以有属性、截图等等 

5.交互动作

```
# 驱动浏览器进行动作，模拟拖拽动作，将动作附加到动作链中串行执行
from selenium import webdriver
from selenium.webdriver import ActionChains#引入动作链 
browser = webdriver.Chrome()
url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'
browser.get(url)
browser.switch_to.frame('iframeResult')#切换到iframeResult框架 
source = browser.find_element_by_css_selector('#draggable')#找到被拖拽对象 
target = browser.find_element_by_css_selector('#droppable')#找到目标 
actions = ActionChains(browser)#声明actions对象 
actions.drag_and_drop(source, target)
actions.perform()#执行动作 
```

6.执行`JavaScript`

有些动作可能没有提供`api`，比如进度条下拉，这时，我们可以通过代码执行`JavaScript`

```
from selenium import webdriver
browser = webdriver.Chrome()
browser.get('https://www.zhihu.com/explore')
browser.execute_script('window.scrollTo(0, document.body.scrollHeight)')
browser.execute_script('alert("To Bottom")')
```

7.获取元素信息

```
# 获取属性
from selenium import webdriver
from selenium.webdriver import ActionChains

browser = webdriver.Chrome()
url = 'https://www.zhihu.com/explore'
browser.get(url)
logo = browser.find_element_by_id('zh-top-link-logo')#获取网站logo 
print(logo)
print(logo.get_attribute('class'))
browser.close()

# 获取文本值
from selenium import webdriver
browser = webdriver.Chrome()
url = 'https://www.zhihu.com/explore'
browser.get(url)
input = browser.find_element_by_class_name('zu-top-add-question')
print(input.text)   # input.text文本值 
browser.close()

# 获取Id，位置，标签名，大小 
from selenium import webdriver
browser = webdriver.Chrome()
url = 'https://www.zhihu.com/explore'
browser.get(url)
input = browser.find_element_by_class_name('zu-top-add-question')
print(input.id)  # 获取id 
print(input.location) # 获取位置 
print(input.tag_name)#获取标签名 
print(input.size)#获取大小 
browser.close()
```

8.`Frame`操作

frame相当于独立的网页，如果在父类网frame查找子类的，则必须切换到子类的frame，子类如果查找父类也需要先切换

```
from selenium import webdriver
from selenium.common.exceptions import NoSuchElementException
browser = webdriver.Chrome()
url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'
browser.get(url)
browser.switch_to.frame('iframeResult')
source = browser.find_element_by_css_selector('#draggable') 
print(source)
try:
  logo = browser.find_element_by_class_name('logo')
except NoSuchElementException:
  print('NO LOGO')
browser.switch_to.parent_frame()
logo = browser.find_element_by_class_name('logo')
print(logo)
print(logo.text)
```

9.等待

隐式等待

当使用了隐式等待执行测试的时候，如果 `WebDriver`没有在 DOM中找到元素，将继续等待，超出设定时间后则抛出找不到元素的异常,

换句话说，当查找元素或元素并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是0

```
from selenium import webdriver
browser = webdriver.Chrome()
browser.implicitly_wait(10)  # 等待十秒加载不出来就会抛出异常，10秒内加载出来正常返回 
browser.get('https://www.zhihu.com/explore')
input = browser.find_element_by_class_name('zu-top-add-question')
print(input)
```

显式等待

指定一个等待条件，和一个最长等待时间，程序会判断在等待时间内条件是否满足，如果满足则返回，如果不满足会继续等待，超过时间就会抛出异常

```
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
browser = webdriver.Chrome()
browser.get('https://www.taobao.com/')
wait = WebDriverWait(browser, 10)
input = wait.until(EC.presence_of_element_located((By.ID, 'q')))
button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.btn-search')))
print(input, button)


```

等待条件

```
title_is 标题是某内容
title_contains 标题包含某内容
presence_of_element_located 元素加载出，传入定位元组，如(By.ID, 'p')
visibility_of_element_located 元素可见，传入定位元组
visibility_of 可见，传入元素对象
presence_of_all_elements_located 所有元素加载出
text_to_be_present_in_element 某个元素文本包含某文字
text_to_be_present_in_element_value 某个元素值包含某文字
frame_to_be_available_and_switch_to_it frame加载并切换
invisibility_of_element_located 元素不可见
element_to_be_clickable 元素可点击
staleness_of 判断一个元素是否仍在DOM，可判断页面是否已经刷新
element_to_be_selected 元素可选择，传元素对象
element_located_to_be_selected 元素可选择，传入定位元组
element_selection_state_to_be 传入元素对象以及状态，相等返回True，否则返回False
element_located_selection_state_to_be 传入定位元组以及状态，相等返回True，否则返回False
alert_is_present 是否出现Alert
```

11.前进后退

实现浏览器的前进后退以浏览不同的网页

```
import time
from selenium import webdriver
browser = webdriver.Chrome()
browser.get('https://www.baidu.com/')
browser.get('https://www.taobao.com/')
browser.get('https://www.python.org/')
browser.back()
time.sleep(1)
browser.forward()
browser.close()
```

12.`Cookies`

```
from selenium import webdriver
browser = webdriver.Chrome()
browser.get('https://www.zhihu.com/explore')
print(browser.get_cookies())
browser.add_cookie({'name': 'name', 'domain': 'www.zhihu.com', 'value': 'germey'})
print(browser.get_cookies())
browser.delete_all_cookies()
print(browser.get_cookies())
```

获取日志

获取头信息

13.选项卡管理 

增加浏览器窗口

```
import time
from selenium import webdriver
browser = webdriver.Chrome()
browser.get('https://www.baidu.com')
browser.execute_script('window.open()')
print(browser.window_handles)
browser.switch_to_window(browser.window_handles[1])
browser.get('https://www.taobao.com')
time.sleep(1)
browser.switch_to_window(browser.window_handles[0])
browser.get('http://www.fishc.com')
```

14.异常处理

```
from selenium import webdriver
browser = webdriver.Chrome()
browser.get('https://www.baidu.com')
browser.find_element_by_id('hello')
from selenium import webdriver
from selenium.common.exceptions import TimeoutException, NoSuchElementException
browser = webdriver.Chrome()
try:
  browser.get('https://www.baidu.com')
except TimeoutException:
  print('Time Out')
try:
  browser.find_element_by_id('hello')
except NoSuchElementException:
  print('No Element')
finally:
  browser.close()
```



## 验证码识别

1.字母验证码

```
import pytesseract
from PIL import Image
import re
from selenium import webdriver
from io import BytesIO

# img = driver.find_element_by_xpath('//img[@id="vcodesrc"]')
# driver = webdriver.Chrome(executable_path="{0}/chromedriver.exe".format(path))
# driver.get("http://admin.dlszywz.cn/login.php###")
def getcaptcha1(img, driver):
    location = img.location
    size = img.size
    top, bottom, left, right = location['y'], location['y'] + size['height'], location['x'], location['x'] + size[
        'width']
    screenshot = driver.get_screenshot_as_png()
    screenshot = Image.open(BytesIO(screenshot))
    captcha = screenshot.crop((left, top, right, bottom))
    captcha.save("captcha.png")
    image = Image.open("./captcha.png")
    code = pytesseract.image_to_string(image)  # 识别验证码
    code = re.sub(u"([^\u4e00-\u9fa5\u0030-\u0039\u0041-\u005a\u0061-\u007a])", "", code)  # 去除识别出来的特殊字符
    code = code[0:4]  # 只获取前4个字符
    return code

# name = "./validate.jpg"
def getcaptcha2(name):
    image = Image.open(name)
    code = pytesseract.image_to_string(image)  # 识别验证码
    code = re.sub(u"([^\u4e00-\u9fa5\u0030-\u0039\u0041-\u005a\u0061-\u007a])", "", code)  # 去除识别出来的特殊字符
    code = code[0:4]  # 只获取前4个字符
    return code
```

## `xpath`

```
xpath https://www.w3school.com.cn/xpath/index.asp
```

解析`html`

```
from lxml import etree
text = '<html>...</html>'  # 不是完整的html也可
html = etree.HTML(text)
html.xpath(....)
```

绝对定位、相对定位

```
html.xpath('/html/head/title/text()')
html.xpath('//div/p/text()')
```

获取节点

```
html.xpath('//*')  # 获取所有节点,//代表子孙节点,*代表所有
html.xpath('//li')  # 获取
html.xpath('//li/a')  # 获取
html.xpath('//li/../..')  # 获取
html.xpath('//li/parent::*/a')  # 获取
html.xpath('//li/../a')  # 获取
```

获取属性

```
html.xpath('//a/@herf')
html.xpath('//img/@src')
```

文本获取

```
html.xpath('//a/text()')
```

属性匹配

```
html.xpath('//div[@id="xxx"]')
html.xpath('//div[@name="xxx"]')
html.xpath('//div[@class="xxx"]')
```

属性部分匹配

```
html.xpath('//div[contains(@class, "xxx")]')
html.xpath('//div[starts-with(@class, "xxx")]') # 以xxx开头
html.xpath('//div[ends-with(@class, "xxx")]')  # 注意可能有问题
```

多属性匹配

```
html.xpath('//a[@class="xxx"][text()="xxx"]')
html.xpath('//a[text()="百度网盘" and @target="_blank"]')
```

文本匹配

```
html.xpath('//a[text()="xxx"]')
```

运算符

| \|   | 并集（两个节点同时拥有的） |
| ---- | -------------------------- |
| +    |                            |
| -    |                            |
| *    | 乘                         |
| div  | 除                         |
| =    |                            |
| ！=  |                            |
| <    |                            |
| <=   |                            |
| >    |                            |
| >=   |                            |
| or   |                            |
| and  |                            |
| mod  | 计算除法的余数             |
|      |                            |

按序选择

```
html.xpath('//li/a/')
html.xpath('//li/a[1]') # 获取第一个
html.xpath('//li/a[2]')
html.xpath('//li/a[last()]') # 获取最后一个
html.xpath('//li/a[last()-1]') # 获取倒数第2个
html.xpath('//li/a[position()>1]') # 获取第二个a(包含)以后的
```

节点轴

使用语法： 轴名称 :: 节点名称

|      |      |
| ---- | ---- |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |



## `lxml`

`lxml`是`python`的一个解析库，支持`HTML`和`XML`的解析，支持`XPath`解析方式

会使用`lxml.etree`库解析网页，再使用`xpath`获取信息

```
lxml  https://www.cnblogs.com/zhangxinqi/p/9210211.html
	  https://lxml.de/lxmlhtml.html
```

```
爬虫过程中，一般会使用requests.get()方法获取一个网页上的HTML内容，然后通过lxml库中的etree.HTML来解析这个网页的结构，最后通过xpath获取自己所需的内容。
from lxml import etree
headers = {****}
url = "https://****"
response = requests.get(url, headers=headers)
html = etree.HTML(response.text)
pic_urls = html.xpath('****') 
```

## `Fidder`

```
https://www.cnblogs.com/yyhh/p/5140852.html
```

## `re`

```
https://www.cnblogs.com/shenjianping/p/11647473.html
```

正则表达式中的三组括号把匹配结果分成三组

-  group() 同group（0）就是匹配正则表达式整体结果
-  group(1) 列出第一个括号匹配部分，group(2) 列出第二个括号匹配部分，group(3) 列出第三个括号匹配部分

## `seleniumwire`

```
https://www.cnblogs.com/startnow/p/14635147.html
https://www.jianshu.com/p/cb420b843d4c
```

## `appnium`

appnium桌面版的安装

```
https://www.cnblogs.com/fnng/p/7683427.html
```

配置

```
https://zhuanlan.zhihu.com/p/49193525
```

安装java

```
https://www.cnblogs.com/bpf-1024/p/13375289.html
```

appium desired_caps参数

```
https://www.cnblogs.com/mrwhite2020/p/13037011.html
```

aapt下载与安装

```
https://blog.csdn.net/weixin_41924879/article/details/109509859
```

aapt 应用信息

```
https://jishuin.proginn.com/p/763bfbd35ff8
```

adb devices unauthorized（未授权）怎么办？

允许usb调试吗？---->是

获取activity 

```
https://blog.csdn.net/qq_27061049/article/details/105412554
```

## 虚拟账号验证码接收

